import asyncio
"""
MCP Server for Archon (Microservices Version)

This is the MCP server that uses HTTP calls to other services
instead of importing heavy dependencies directly. This significantly reduces
the container size from 1.66GB to ~150MB.

Modules:
- RAG Module: RAG queries, search, and source management via HTTP
- Project Module: Task and project management via HTTP
- Health & Session: Local operations

Note: Crawling and document upload operations are handled directly by the
API service and frontend, not through MCP tools.
"""

import json
import logging
import os
import sys
import threading
import time
import traceback
from collections.abc import AsyncIterator
from contextlib import asynccontextmanager
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any

from dotenv import load_dotenv
from mcp.server.fastmcp import Context, FastMCP
from starlette.requests import Request
from starlette.responses import JSONResponse

# Add the project root to Python path for imports
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

# Load environment variables from the project root .env file
project_root = Path(__file__).resolve().parent.parent
dotenv_path = project_root / ".env"
load_dotenv(dotenv_path, override=True)

# Configure logging FIRST before any imports that might use it
# Check if we're in stdio mode - if so, only log to file, not stdout
transport_mode = os.getenv("TRANSPORT", "streamable-http")
log_level = getattr(logging, os.getenv("LOG_LEVEL", "INFO").upper(), logging.INFO)

handlers = []
if transport_mode != "stdio":
    # Only log to stdout if NOT in stdio mode (to avoid breaking MCP protocol)
    handlers.append(logging.StreamHandler(sys.stdout))

# Always try to log to file
if os.path.exists("/tmp"):
    handlers.append(logging.FileHandler("/tmp/mcp_server.log", mode="a"))

if not handlers:
    handlers.append(logging.NullHandler())

logging.basicConfig(
    level=log_level,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=handlers,
)
logger = logging.getLogger(__name__)

# Import Logfire configuration
from src.server.config.logfire_config import mcp_logger, setup_logfire

# Import service client for HTTP calls
from src.server.services.mcp_service_client import get_mcp_service_client

# Import session management
from src.server.services.mcp_session_manager import get_session_manager

# Global initialization lock and flag
_initialization_lock = threading.Lock()
_initialization_complete = False
_shared_context = None

server_host = "0.0.0.0"  # Listen on all interfaces

# Require ARCHON_MCP_PORT to be set
mcp_port = os.getenv("ARCHON_MCP_PORT")
if not mcp_port:
    raise ValueError(
        "ARCHON_MCP_PORT environment variable is required. "
        "Please set it in your .env file or environment. "
        "Default value: 8051"
    )
server_port = int(mcp_port)


@dataclass
class ArchonContext:
    """
    Context for MCP server.
    No heavy dependencies - just service client for HTTP calls.
    """

    service_client: Any
    health_status: dict = None
    startup_time: float = None

    def __post_init__(self):
        if self.health_status is None:
            self.health_status = {
                "status": "healthy",
                "api_service": False,
                "agents_service": False,
                "last_health_check": None,
            }
        if self.startup_time is None:
            self.startup_time = time.time()


async def perform_health_checks(context: ArchonContext, retry: bool = False, max_retries: int = 10, delay: float = 2.0):
    """Perform health checks on dependent services via HTTP with optional retries."""
    retries = 0
    while True:
        try:
            # Check dependent services
            service_health = await context.service_client.health_check()

            context.health_status["api_service"] = service_health.get("api_service", False)
            context.health_status["agents_service"] = service_health.get("agents_service", False)

            # Overall status
            all_critical_ready = context.health_status["api_service"]

            if all_critical_ready:
                context.health_status["status"] = "healthy"
                context.health_status["last_health_check"] = datetime.now().isoformat()
                logger.info("Health check passed - dependent services healthy")
                return True
            
            if not retry or retries >= max_retries:
                context.health_status["status"] = "degraded"
                context.health_status["last_health_check"] = datetime.now().isoformat()
                logger.warning(f"Health check failed (attempt {retries+1}/{max_retries+1}): {context.health_status}")
                return False

        except Exception as e:
            logger.error(f"Health check error (attempt {retries+1}/{max_retries+1}): {e}")
            if not retry or retries >= max_retries:
                context.health_status["status"] = "unhealthy"
                context.health_status["last_health_check"] = datetime.now().isoformat()
                return False

        retries += 1
        logger.info(f"â³ Waiting for backend services... (attempt {retries}/{max_retries}, sleeping {delay}s)")
        await asyncio.sleep(delay)


@asynccontextmanager
async def lifespan(server: FastMCP) -> AsyncIterator[ArchonContext]:
    """
    Lifecycle manager - no heavy dependencies.
    """
    global _initialization_complete, _shared_context

    # Quick check without lock
    if _initialization_complete and _shared_context:
        logger.info("â™»ï¸ Reusing existing context for new SSE connection")
        yield _shared_context
        return

    # Acquire lock for initialization
    with _initialization_lock:
        # Double-check pattern
        if _initialization_complete and _shared_context:
            logger.info("â™»ï¸ Reusing existing context for new SSE connection")
            yield _shared_context
            return

        logger.info("ðŸš€ Starting MCP server...")

        try:
            # Initialize session manager
            logger.info("ðŸ” Initializing session manager...")
            session_manager = get_session_manager()
            logger.info("âœ“ Session manager initialized")

            # Initialize service client for HTTP calls
            logger.info("ðŸŒ Initializing service client...")
            service_client = get_mcp_service_client()
            logger.info("âœ“ Service client initialized")

            # Create context
            context = ArchonContext(service_client=service_client)

            # Perform initial health check with retries - block until backend is ready
            logger.info("ðŸ¤ Performing initial handshake with backend services...")
            await perform_health_checks(context, retry=True, max_retries=30, delay=3.0)

            logger.info("âœ“ MCP server initialization complete and verified")

            # Store context globally
            _shared_context = context
            _initialization_complete = True

            yield context

        except Exception as e:
            logger.error(f"ðŸ’¥ Critical error in lifespan setup: {e}")
            logger.error(traceback.format_exc())
            # Ensure we reset initialization flag on failure
            _initialization_complete = False
            raise
        finally:
            # Clean up resources
            logger.info("ðŸ§¹ Cleaning up MCP server connection resources...")
            # Note: We don't reset _initialization_complete here as we want to reuse 
            # the context for other connections if this was just one connection closing
            logger.info("âœ… MCP lifespan turn complete")


# Define MCP instructions for Claude Code and other clients
MCP_INSTRUCTIONS = """
# Archon MCP Server Instructions

## ðŸš¨ CRITICAL RULES (ALWAYS FOLLOW)
1. **Task Management**: ALWAYS use Archon MCP tools for task management.
   - Combine with your local TODO tools for granular tracking

2. **Research First**: Before implementing, use rag_search_knowledge_base and rag_search_code_examples
3. **Task-Driven Development**: Never code without checking current tasks first

## ðŸŽ¯ Targeted Documentation Search

When searching specific documentation (very common!):
1. **Get available sources**: `rag_get_available_sources()` - Returns list with id, title, url
2. **Find source ID**: Match user's request to source title (e.g., "PydanticAI docs" -> find ID)
3. **Filter search**: `rag_search_knowledge_base(query="...", source_id="src_xxx", match_count=5)`

Examples:
- User: "Search the Supabase docs for vector functions"
  1. Call `rag_get_available_sources()`
  2. Find Supabase source ID from results (e.g., "src_abc123")
  3. Call `rag_search_knowledge_base(query="vector functions", source_id="src_abc123")`

- User: "Find authentication examples in the MCP documentation"
  1. Call `rag_get_available_sources()`
  2. Find MCP docs source ID
  3. Call `rag_search_code_examples(query="authentication", source_id="src_def456")`

IMPORTANT: Always use source_id (not URLs or domain names) for filtering!

## ðŸ“‹ Core Workflow

### Task Management Cycle
1. **Get current task**: `list_tasks(task_id="...")` 
2. **Search/List tasks**: `list_tasks(query="auth", filter_by="status", filter_value="todo")`
3. **Mark as doing**: `manage_task("update", task_id="...", status="doing")`
4. **Research phase**:
   - `rag_search_knowledge_base(query="...", match_count=5)`
   - `rag_search_code_examples(query="...", match_count=3)`
5. **Implementation**: Code based on research findings
6. **Mark for review**: `manage_task("update", task_id="...", status="review")`
7. **Get next task**: `list_tasks(filter_by="status", filter_value="todo")`

### Consolidated Task Tools (Optimized ~2 tools from 5)
- `list_tasks(query=None, task_id=None, filter_by=None, filter_value=None, per_page=10)`
  - list + search + get in one tool
  - Search with keyword query parameter (optional)
  - task_id parameter for getting single task (full details)
  - Filter by status, project, or assignee
  - **Optimized**: Returns truncated descriptions and array counts (lists only)
  - **Default**: 10 items per page (was 50)
- `manage_task(action, task_id=None, project_id=None, ...)`
  - **Consolidated**: create + update + delete in one tool
  - action: "create" | "update" | "delete"
  - Examples:
    - `manage_task("create", project_id="p-1", title="Fix auth")`
    - `manage_task("update", task_id="t-1", status="doing")`
    - `manage_task("delete", task_id="t-1")`

## ðŸ—ï¸ Project Management

### Project Tools
- `list_projects(project_id=None, query=None, page=1, per_page=10)`
  - List all projects, search by query, or get specific project by ID
- `manage_project(action, project_id=None, title=None, description=None, github_repo=None)`
  - Actions: "create", "update", "delete"

### Document Tools
- `list_documents(project_id, document_id=None, query=None, document_type=None, page=1, per_page=10)`
  - List project documents, search, filter by type, or get specific document
- `manage_document(action, project_id, document_id=None, title=None, document_type=None, content=None, ...)`
  - Actions: "create", "update", "delete"

## ðŸ” Research Patterns

### CRITICAL: Keep Queries Short and Focused!
Vector search works best with 2-5 keywords, NOT long sentences or keyword dumps.

âœ… GOOD Queries (concise, focused):
- `rag_search_knowledge_base(query="vector search pgvector")`
- `rag_search_code_examples(query="React useState")`
- `rag_search_knowledge_base(query="authentication JWT")`
- `rag_search_code_examples(query="FastAPI middleware")`

âŒ BAD Queries (too long, unfocused):
- `rag_search_knowledge_base(query="how to implement vector search with pgvector in PostgreSQL for semantic similarity matching with OpenAI embeddings")`
- `rag_search_code_examples(query="React hooks useState useEffect useContext useReducer useMemo useCallback")`

### Query Construction Tips:
- Extract 2-5 most important keywords from the user's request
- Focus on technical terms and specific technologies
- Omit filler words like "how to", "implement", "create", "example"
- For multi-concept searches, do multiple focused queries instead of one broad query

## ðŸ“Š Task Status Flow
`todo` â†’ `doing` â†’ `review` â†’ `done`
- Only ONE task in 'doing' status at a time
- Use 'review' for completed work awaiting validation
- Mark tasks 'done' only after verification

## ðŸ“ Task Granularity Guidelines

### Project Scope Determines Task Granularity

**For Feature-Specific Projects** (project = single feature):
Create granular implementation tasks:
- "Set up development environment"
- "Install required dependencies"
- "Create database schema"
- "Implement API endpoints"
- "Add frontend components"
- "Write unit tests"
- "Add integration tests"
- "Update documentation"

**For Codebase-Wide Projects** (project = entire application):
Create feature-level tasks:
- "Implement user authentication feature"
- "Add payment processing system"
- "Create admin dashboard"
"""

# Initialize the main FastMCP server with fixed configuration
try:
    logger.info("ðŸ—ï¸ MCP SERVER INITIALIZATION:")
    logger.info("   Server Name: archon-mcp-server")
    logger.info("   Description: MCP server using HTTP calls")

    mcp = FastMCP(
        "archon-mcp-server",
        description="MCP server for Archon - uses HTTP calls to other services",
        instructions=MCP_INSTRUCTIONS,
        lifespan=lifespan,
        host=server_host,
        port=server_port,
    )
    logger.info("âœ“ FastMCP server instance created successfully")

except Exception as e:
    logger.error(f"âœ— Failed to create FastMCP server: {e}")
    logger.error(traceback.format_exc())
    raise


# Health check endpoint
@mcp.tool()
async def health_check(ctx: Context) -> str:
    """
    Check health status of MCP server and dependencies.

    Returns:
        JSON with health status, uptime, and service availability
    """
    try:
        # Try to get the lifespan context
        context = getattr(ctx.request_context, "lifespan_context", None)

        if context is None:
            # Server starting up
            return json.dumps({
                "success": True,
                "status": "starting",
                "message": "MCP server is initializing...",
                "timestamp": datetime.now().isoformat(),
            })

        # Server is ready - perform health checks
        if hasattr(context, "health_status") and context.health_status:
            await perform_health_checks(context)

            return json.dumps({
                "success": True,
                "health": context.health_status,
                "uptime_seconds": time.time() - context.startup_time,
                "timestamp": datetime.now().isoformat(),
            })
        else:
            return json.dumps({
                "success": True,
                "status": "ready",
                "message": "MCP server is running",
                "timestamp": datetime.now().isoformat(),
            })

    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return json.dumps({
            "success": False,
            "error": f"Health check failed: {str(e)}",
            "timestamp": datetime.now().isoformat(),
        })


# Session management endpoint
@mcp.tool()
async def session_info(ctx: Context) -> str:
    """
    Get current and active session information.

    Returns:
        JSON with active sessions count and server uptime
    """
    try:
        session_manager = get_session_manager()

        # Build session info
        session_info_data = {
            "active_sessions": session_manager.get_active_session_count(),
            "session_timeout": session_manager.timeout,
        }

        # Add server uptime
        context = getattr(ctx.request_context, "lifespan_context", None)
        if context and hasattr(context, "startup_time"):
            session_info_data["server_uptime_seconds"] = time.time() - context.startup_time

        return json.dumps({
            "success": True,
            "session_management": session_info_data,
            "timestamp": datetime.now().isoformat(),
        })

    except Exception as e:
        logger.error(f"Session info failed: {e}")
        return json.dumps({
            "success": False,
            "error": f"Failed to get session info: {str(e)}",
            "timestamp": datetime.now().isoformat(),
        })


# Import and register modules
def register_modules():
    """Register all MCP tool modules."""
    logger.info("ðŸ”§ Registering MCP tool modules...")

    modules_registered = 0

    # Import and register RAG module (HTTP-based version)
    try:
        from src.mcp_server.features.rag import register_rag_tools

        register_rag_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ RAG module registered (HTTP-based)")
    except ImportError as e:
        logger.warning(f"âš  RAG module not available: {e}")
    except Exception as e:
        logger.error(f"âœ— Error registering RAG module: {e}")
        logger.error(traceback.format_exc())

    # Import and register all feature tools - separated and focused

    # Project Management Tools
    try:
        from src.mcp_server.features.projects import register_project_tools

        register_project_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Project tools registered")
    except ImportError as e:
        # Module not found - this is acceptable in modular architecture
        logger.warning(f"âš  Project tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        # Code errors that should not be ignored
        logger.error(f"âœ— Code error in project tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise  # Re-raise to prevent running with broken code
    except Exception as e:
        # Unexpected errors during registration
        logger.error(f"âœ— Failed to register project tools: {e}")
        logger.error(traceback.format_exc())
        # Don't raise - allow other modules to register

    # Task Management Tools
    try:
        from src.mcp_server.features.tasks import register_task_tools

        register_task_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Task tools registered")
    except ImportError as e:
        logger.warning(f"âš  Task tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in task tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register task tools: {e}")
        logger.error(traceback.format_exc())

    # Session Management Tools
    try:
        from src.mcp_server.features.sessions import register_session_tools

        register_session_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Session tools registered")
    except ImportError as e:
        logger.warning(f"âš  Session tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in session tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register session tools: {e}")
        logger.error(traceback.format_exc())

    # Pattern Management Tools
    try:
        from src.mcp_server.features.patterns import register_pattern_tools

        register_pattern_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Pattern tools registered")
    except ImportError as e:
        logger.warning(f"âš  Pattern tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in pattern tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register pattern tools: {e}")
        logger.error(traceback.format_exc())

    # Agent Registry Tools
    try:
        from src.mcp_server.features.agents import register_agent_tools

        register_agent_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Agent registry tools registered")
    except ImportError as e:
        logger.warning(f"âš  Agent registry tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in agent registry tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register agent registry tools: {e}")
        logger.error(traceback.format_exc())

    # Shared Context Tools
    try:
        from src.mcp_server.features.context import register_context_tools

        register_context_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Shared context tools registered")
    except ImportError as e:
        logger.warning(f"âš  Shared context tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in shared context tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register shared context tools: {e}")
        logger.error(traceback.format_exc())

    # Handoff Tools
    try:
        from src.mcp_server.features.handoffs import register_handoff_tools

        register_handoff_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Handoff tools registered")
    except ImportError as e:
        logger.warning(f"âš  Handoff tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in handoff tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register handoff tools: {e}")
        logger.error(traceback.format_exc())

    # Document Management Tools
    try:
        from src.mcp_server.features.documents import register_document_tools

        register_document_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Document tools registered")
    except ImportError as e:
        logger.warning(f"âš  Document tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in document tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register document tools: {e}")
        logger.error(traceback.format_exc())

    # Version Management Tools
    try:
        from src.mcp_server.features.documents import register_version_tools

        register_version_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Version tools registered")
    except ImportError as e:
        logger.warning(f"âš  Version tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in version tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register version tools: {e}")
        logger.error(traceback.format_exc())

    # Feature Management Tools
    try:
        from src.mcp_server.features.feature_tools import register_feature_tools

        register_feature_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Feature tools registered")
    except ImportError as e:
        logger.warning(f"âš  Feature tools module not available (optional): {e}")
    except (SyntaxError, NameError, AttributeError) as e:
        logger.error(f"âœ— Code error in feature tools - MUST FIX: {e}")
        logger.error(traceback.format_exc())
        raise
    except Exception as e:
        logger.error(f"âœ— Failed to register feature tools: {e}")
        logger.error(traceback.format_exc())


    # Application Management Tools
    try:
        from src.mcp_server.features.apps import register_app_tools

        register_app_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ App tools registered")
    except ImportError as e:
        logger.warning(f"âš  App tools module not available (optional): {e}")
    except Exception as e:
        logger.error(f"âœ— Failed to register app tools: {e}")
        logger.error(traceback.format_exc())

    # Conductor Log Tools
    try:
        from src.mcp_server.features.conductor_log import register_conductor_log_tools

        register_conductor_log_tools(mcp)
        modules_registered += 1
        logger.info("âœ“ Conductor log tools registered")
    except ImportError as e:
        logger.warning(f"âš  Conductor log tools module not available (optional): {e}")
    except Exception as e:
        logger.error(f"âœ— Failed to register conductor log tools: {e}")
        logger.error(traceback.format_exc())

    logger.info(f"ðŸ“¦ Total modules registered: {modules_registered}")

    if modules_registered == 0:
        logger.error("ðŸ’¥ No modules were successfully registered!")
        raise RuntimeError("No MCP modules available")


# Register all modules when this file is imported
try:
    register_modules()
except Exception as e:
    logger.error(f"ðŸ’¥ Critical error during module registration: {e}")
    logger.error(traceback.format_exc())
    raise


# Track server start time at module level for health checks
_server_start_time = time.time()


# Define health endpoint function at module level
async def http_health_endpoint(request: Request):
    """HTTP health check endpoint for monitoring systems."""
    logger.info("Health endpoint called via HTTP")
    try:
        # Try to get the shared context for detailed health info
        if _shared_context and hasattr(_shared_context, "health_status"):
            # Use actual server startup time for consistency with MCP health_check tool
            uptime = time.time() - _shared_context.startup_time
            await perform_health_checks(_shared_context)

            return JSONResponse({
                "success": True,
                "health": _shared_context.health_status,
                "uptime_seconds": uptime,
                "timestamp": datetime.now().isoformat(),
            })
        else:
            # Server starting up or no MCP connections yet - use module load time as fallback
            uptime = time.time() - _server_start_time
            return JSONResponse({
                "success": True,
                "status": "ready",
                "uptime_seconds": uptime,
                "message": "MCP server is running (no active connections yet)",
                "timestamp": datetime.now().isoformat(),
            })
    except Exception as e:
        logger.error(f"HTTP health check failed: {e}", exc_info=True)
        return JSONResponse({
            "success": False,
            "error": f"Health check failed: {str(e)}",
            "uptime_seconds": time.time() - _server_start_time,
            "timestamp": datetime.now().isoformat(),
        }, status_code=500)


# Register health endpoint using FastMCP's custom_route decorator
try:
    mcp.custom_route("/health", methods=["GET"])(http_health_endpoint)
    logger.info("âœ“ HTTP /health endpoint registered successfully")
except Exception as e:
    logger.error(f"âœ— Failed to register /health endpoint: {e}")
    logger.error(traceback.format_exc())


def main():
    """Main entry point for the MCP server."""
    try:
        # Initialize Logfire first
        setup_logfire(service_name="archon-mcp-server")

        # Get transport mode from environment variable (default: streamable-http)
        transport = os.getenv("TRANSPORT", "streamable-http")

        logger.info("ðŸš€ Starting Archon MCP Server")
        logger.info(f"   Mode: {transport.upper()}")
        if transport == "streamable-http":
            logger.info(f"   URL: http://{server_host}:{server_port}/mcp")

        mcp_logger.info("ðŸ”¥ Logfire initialized for MCP server")
        mcp_logger.info(f"ðŸŒŸ Starting MCP server - host={server_host}, port={server_port}, transport={transport}")

        mcp.run(transport=transport)

    except Exception as e:
        mcp_logger.error(f"ðŸ’¥ Fatal error in main - error={str(e)}, error_type={type(e).__name__}")
        logger.error(f"ðŸ’¥ Fatal error in main: {e}")
        logger.error(traceback.format_exc())
        raise


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("ðŸ‘‹ MCP server stopped by user")
    except Exception as e:
        logger.error(f"ðŸ’¥ Unhandled exception: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)
